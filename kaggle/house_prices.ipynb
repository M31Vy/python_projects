{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005f952a-08ec-42de-ac39-2b09fe35dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import wandb\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features,256)\n",
    "        self.layer2 = nn.Linear(256,64)\n",
    "        self.out = nn.Linear(64,1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.layer1(X))\n",
    "        X = F.relu(self.layer2(X))\n",
    "        return self.out(X)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140f60cd-d36c-41f2-b176-1accc322459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def log_rmse(net, features, labels):\n",
    "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
    "    rmse = torch.sqrt(criterion(torch.log(clipped_preds),\n",
    "                           torch.log(labels)))\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7a457e-6fac-416f-9234-eb70f0d626c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data and test_data shape (47439, 41) (31626, 40)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "print(\"train_data and test_data shape\",train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b95cae-a30e-423a-b8f7-afc7b865ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_cols = ['Address', 'Summary', 'City', 'State']\n",
    "for c in redundant_cols:\n",
    "    del test_data[c], train_data[c]\n",
    "\n",
    "# 数据预处理\n",
    "large_vel_cols = ['Lot', 'Total interior livable area', 'Tax assessed value', 'Annual tax amount', 'Listed Price', 'Last Sold Price']\n",
    "for c in large_vel_cols:\n",
    "    train_data[c] = np.log(train_data[c]+1)\n",
    "    test_data[c] = np.log(test_data[c]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5d70bf-57b4-4177-8aa1-a422892331c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除部分特征(ID,Address,summary)\n",
    "all_features = pd.concat((train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d90e6a8-c2d9-4d26-9c4b-6235f9c49257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M31Vy\\AppData\\Local\\Temp\\ipykernel_16100\\3725493553.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  all_features = all_features.fillna(method='bfill', axis=0).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# 查询数字列 ->缺失数据赋0 -> 归一化\n",
    "numeric_features = all_features.dtypes[all_features.dtypes == 'float64'].index\n",
    "all_features = all_features.fillna(method='bfill', axis=0).fillna(0)\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e27a0ac-1a42-4a5f-915a-13db3b455b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                 174\n",
      "Heating              2658\n",
      "Cooling              909\n",
      "Parking              9911\n",
      "Bedrooms             277\n",
      "Region               1258\n",
      "Elementary School    3567\n",
      "Middle School        809\n",
      "High School          921\n",
      "Flooring             1738\n",
      "Heating features     1761\n",
      "Cooling features     594\n",
      "Appliances included  11289\n",
      "Laundry features     3029\n",
      "Parking features     9693\n",
      "Listed On            2815\n",
      "Last Sold On         6948\n"
     ]
    }
   ],
   "source": [
    "for in_object in all_features.dtypes[all_features.dtypes=='object'].index:\n",
    "    print(in_object.ljust(20),len(all_features[in_object].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b155f94d-5b2b-4222-b642-8699f0329697",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(numeric_features)\n",
    "# 加上类别数相对较少的Type\n",
    "features.extend(['Type','Bedrooms'])\n",
    "all_features = all_features[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be904792-13e3-44b1-a4f5-5276cafd7acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before one hot code (79065, 20)\n",
      "after one hot code (79065, 471)\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('before one hot code',all_features.shape)\n",
    "all_features = pd.get_dummies(all_features,dummy_na=True)\n",
    "print('after one hot code',all_features.shape)\n",
    "\n",
    "non_float_cols = all_features.dtypes[all_features.dtypes!='float'].index\n",
    "non_bool_cols = all_features.dtypes[all_features.dtypes!='bool'].index\n",
    "non_complex_cols = all_features.dtypes[all_features.dtypes!='complex'].index\n",
    "non_int_cols = all_features.dtypes[all_features.dtypes!='int'].index\n",
    "non_numeric_cols = non_float_cols.intersection(non_bool_cols).intersection(non_complex_cols).intersection(non_int_cols)\n",
    "print(non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad310b9-336b-46f1-8ec5-93c14e89e3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 79065 entries, 0 to 31625\n",
      "Columns: 471 entries, Sold Price to Bedrooms_nan\n",
      "dtypes: bool(453), float64(18)\n",
      "memory usage: 45.6 MB\n"
     ]
    }
   ],
   "source": [
    "all_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f1cca9-6784-4cf3-ace0-16af9fe9b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train feature shape: torch.Size([47439, 471])\n",
      "test feature shape: torch.Size([31626, 471])\n",
      "train label shape: torch.Size([47439, 1])\n"
     ]
    }
   ],
   "source": [
    "# 将 'bool' 列转换为 'int' 类型\n",
    "all_features = all_features.astype({col: 'int' for col in all_features.columns if all_features[col].dtype == 'bool'})\n",
    "\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float)\n",
    "print('train feature shape:', train_features.shape)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float)\n",
    "print('test feature shape:', test_features.shape)\n",
    "train_labels = torch.tensor(train_data['Sold Price'].values.reshape(-1, 1), dtype=torch.float)\n",
    "print('train label shape:', train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de365e7c-824f-4179-ae47-965b1d5ea23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db1e1b42-eec2-4363-a219-e6a99c232439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhangyudai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\python_work\\gpt\\kaggle\\california-house-prices\\wandb\\run-20240315_013426-pze8lrez</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangyudai/kaggle_predict/runs/pze8lrez' target=\"_blank\">turtle-flan-3</a></strong> to <a href='https://wandb.ai/hangyudai/kaggle_predict' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangyudai/kaggle_predict' target=\"_blank\">https://wandb.ai/hangyudai/kaggle_predict</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangyudai/kaggle_predict/runs/pze8lrez' target=\"_blank\">https://wandb.ai/hangyudai/kaggle_predict/runs/pze8lrez</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network: MLP(\n",
      "  (layer1): Linear(in_features=471, out_features=256, bias=True)\n",
      "  (layer2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_features = train_features.shape[1]\n",
    "net = MLP(in_features).to(device)\n",
    "\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    wandb.watch(net)\n",
    "    train_ls, test_ls = [], []\n",
    "    train_iter = load_array((train_features, train_labels), batch_size)\n",
    "    # 这里使用的是Adam优化算法\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        record_loss = log_rmse(net.to('cpu'), train_features, train_labels)\n",
    "        wandb.log({'loss': record_loss,'epoch': epoch})\n",
    "        train_ls.append(record_loss)\n",
    "        if (epoch%NUM_SAVE==0 and epoch!=0) or (epoch==num_epochs-1):\n",
    "            torch.save(net.state_dict(),'checkpoint_'+str(epoch))\n",
    "            print('save checkpoints on:', epoch, 'rmse loss value is:', record_loss)\n",
    "        del X, y\n",
    "        net.to(device)\n",
    "    wandb.finish()\n",
    "    return train_ls, test_ls\n",
    "\n",
    "# 初始化wandb 进行记录\n",
    "num_epochs, lr, weight_decay, batch_size = 500, 0.005, 0.05, 256\n",
    "wandb.init(project=\"kaggle_predict\",\n",
    "           config={ \"learning_rate\": lr,\n",
    "                    \"weight_decay\": weight_decay,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"total_run\": num_epochs,\n",
    "                    \"network\": net}\n",
    "          )\n",
    "print(\"network:\",net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f53d42-32ef-4707-b433-f847122bb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▊                                                                                               | 51/500 [01:07<09:43,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 50 rmse loss value is: 0.017087794840335846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████▏                                                                                   | 101/500 [02:15<09:07,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 100 rmse loss value is: 0.006886149290949106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████▋                                                                         | 151/500 [03:22<07:34,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 150 rmse loss value is: 0.007267992477864027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████▏                                                              | 201/500 [04:28<06:37,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 200 rmse loss value is: 0.005585211329162121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████▋                                                    | 251/500 [05:36<05:36,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 250 rmse loss value is: 0.005913734436035156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████▏                                         | 301/500 [06:42<04:21,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 300 rmse loss value is: 0.0027881860733032227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████▋                               | 351/500 [07:50<03:19,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 350 rmse loss value is: 0.0037927052471786737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████▏                    | 401/500 [08:56<02:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 400 rmse loss value is: 0.002963532693684101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████▋          | 451/500 [10:03<01:04,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 450 rmse loss value is: 0.004835514351725578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [11:08<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 499 rmse loss value is: 0.005292905494570732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>499</td></tr><tr><td>loss</td><td>0.00529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">turtle-flan-3</strong> at: <a href='https://wandb.ai/hangyudai/kaggle_predict/runs/pze8lrez' target=\"_blank\">https://wandb.ai/hangyudai/kaggle_predict/runs/pze8lrez</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240315_013426-pze8lrez\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_SAVE = 50  # 每隔 10 个 epoch 保存一次模型的检查点\n",
    "\n",
    "train_ls, valid_ls = train(net, train_features,train_labels,None,None, num_epochs, lr, weight_decay, batch_size)\n",
    "\n",
    "# 使用现有训练好的net\n",
    "net.to(device)\n",
    "# 将网络应用于测试集。\n",
    "preds = net(test_features).detach().numpy()\n",
    "\n",
    "# 将其重新格式化以导出到Kaggle\n",
    "test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2f537-2bc5-4fb7-b723-c4d0f148ef0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
